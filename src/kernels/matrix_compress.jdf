extern "C" %{
/**
 * @copyright (c) 2023-2025     Saint Louis University (SLU)
 * @copyright (c) 2023-2025     Massachusetts Institute of Technology (MIT)
 * @copyright (c) 2023-2025     Nvidia Corporation
 * @copyright (c) 2018-2025     King Abdullah University of Science and Technology (KAUST)
 * @copyright (c) 2018-2023     The University of Tennessee and The University of Tennessee Research Foundation
 *                              All rights reserved.
 **/

#include "hicma_parsec.h"

%}

/** Matrix compression and low-rank approximation generation
 * This file implements matrix compression using low-rank approximations
 * for off-diagonal tiles and dense storage for diagonal/band tiles
 */

/* Global parameters for matrix compression */
descA           [ type = "parsec_tiled_matrix_t*" ]  /* Matrix descriptor */
descAr          [ type = "parsec_tiled_matrix_t*" ]  /* Rank matrix descriptor */
params_tlr      [ type = "hicma_parsec_params_t *" ] /* TLR parameters */
params_kernel   [ type = "starsh_params_t *" ]       /* Kernel parameters */

norm            [ type = "double *" hidden = on ]    /* Norm accumulation array */
rsvd_oversample [ type = "int" hidden = on ]         /* RSVD oversampling parameter */
rsvd_lwork      [ type = "size_t" hidden = on ]      /* RSVD work space size */
rsvd_liwork     [ type = "size_t" hidden = on ]      /* RSVD integer work space size */
uv_work         [ type = "parsec_memory_pool_t *" hidden = on default = NULL] /* UV workspace */
d_work          [ type = "parsec_memory_pool_t *" hidden = on default = NULL] /* Double precision workspace */
rsvd_work       [ type = "parsec_memory_pool_t *" hidden = on default = NULL] /* RSVD workspace */
rsvd_iwork      [ type = "parsec_memory_pool_t *" hidden = on default = NULL] /* RSVD integer workspace */

/**************************************************
 *        Generate diagonal/band tiles            *
 * Generates dense tiles for the diagonal band    *
 **************************************************/
generate_band(m, n) [high_priority = on]

// Execution space - process tiles within the dense band
m = 0 .. descA->mt-1
n = %{ return parsec_imax(m-params_tlr->band_size_dense+1, 0); %} .. m 

// Parallel partitioning
:descA(m, n)

// Parameters
RW D <- descA(m, n)               
     -> descA(m, n)     
READ D1 <- NULL                       [ type_remote = FULL ]

BODY
{
    int ldd = BLKLDD(descA, m);
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int tempnn = tempmm;

    /* Allocate memory for band tiles if not using contiguous memory layout */
#if !BAND_MEMORY_CONTIGUOUS && !GENOMICS
    if( params_tlr->band_size_dense <= descA->nt || params_tlr->auto_band || params_tlr->adaptive_memory ) {
        // Create new data copy for this tile
        this_task->data._f_D.data_out = parsec_data_copy_new(data_of_descA(m, n), 0, PARSEC_matrix_compress_FULL_ADT->opaque_dtt, PARSEC_DATA_FLAG_PARSEC_MANAGED);
        if( params_tlr->gpus > 0 ) {
            
#if defined(PARSEC_HAVE_DEV_CUDA_SUPPORT)
            // Allocate pinned host memory for GPU operations
            if( IS_ALLOCATE_DP(m, n) ) { 
                //printf("(%d %d) Allocate in DP\n", m, n);
                cudaMallocHost((void**)&this_task->data._f_D.data_out->device_private, descA->mb * descA->mb * sizeof(double));
                this_task->data._f_D.data_out->original->nb_elts = descA->mb * descA->mb * sizeof(double);
            } else {
                //printf("(%d %d) Allocate in SP\n", m, n);
                cudaMallocHost((void**)&this_task->data._f_D.data_out->device_private, descA->mb * descA->mb * sizeof(float));
                this_task->data._f_D.data_out->original->nb_elts = descA->mb * descA->mb * sizeof(float);
            }
#endif

#if defined(PARSEC_HAVE_DEV_HIP_SUPPORT)
            // Allocate pinned host memory for HIP operations
            if( IS_ALLOCATE_DP(m, n) ) { 
                hipHostMalloc((void**)&this_task->data._f_D.data_out->device_private, descA->mb * descA->mb * sizeof(double), hipHostMallocDefault);
                this_task->data._f_D.data_out->original->nb_elts = descA->mb * descA->mb * sizeof(double);
            } else {
                hipHostMalloc((void**)&this_task->data._f_D.data_out->device_private, descA->mb * descA->mb * sizeof(float), hipHostMallocDefault);
                this_task->data._f_D.data_out->original->nb_elts = descA->mb * descA->mb * sizeof(float);
            }
            // hipHostMallocNumaUser
            // https://github.com/ROCm-Developer-Tools/HIP/issues/2475
            // https://rocm-developer-tools.github.io/HIP/group__GlobalDefs.html
            //this_task->data._f_D.data_out->device_private = calloc(descA->mb * descA->mb, sizeof(double));
#endif
        } 
        else {
            // Allocate regular host memory for CPU operations
            if( IS_ALLOCATE_DP(m, n) ) { 
                this_task->data._f_D.data_out->device_private = calloc(descA->mb * descA->mb, sizeof(double));
                this_task->data._f_D.data_out->original->nb_elts = descA->mb * descA->mb * sizeof(double);
            } else {
                this_task->data._f_D.data_out->device_private = calloc(descA->mb * descA->mb, sizeof(float));
                this_task->data._f_D.data_out->original->nb_elts = descA->mb * descA->mb * sizeof(float);
            }
        }
    }
#endif // !BAND_MEMORY_CONTIGUOUS

    // Generate matrix data based on configuration
#if GENERATE_RANDOM_DATA 
    // Generate random symmetric positive definite matrix
    if( IS_ALLOCATE_DP(m, n) ) { 
        CORE_dplgsy(
                params_tlr->N, tempmm, tempnn, this_task->data._f_D.data_out->device_private, ldd,
                descA->m, m*descA->mb, n*descA->nb, 3872 );
    } else {
        CORE_splgsy(
                params_tlr->N, tempmm, tempnn, this_task->data._f_D.data_out->device_private, ldd,
                descA->m, m*descA->mb, n*descA->nb, 3872 );
    }
#elif !GENOMICS
    // Generate matrix using kernel function
    params_kernel->kernel(tempmm, tempnn, params_kernel->index + m*descA->mb,
            params_kernel->index + n*descA->mb, params_kernel->data, params_kernel->data,
            this_task->data._f_D.data_out->device_private, ldd);
#endif

    /* Add diagonal correction to ensure positive definiteness */ 
    if(m == n) {
        if( IS_ALLOCATE_DP(m, n) ) {
            for(int i = 0; i < descA->mb; i++) {
                ((double *)this_task->data._f_D.data_out->device_private)[i*descA->mb+i] += params_tlr->add_diag;
            }
        } else {
            for(int i = 0; i < descA->mb; i++) {
                ((float *)this_task->data._f_D.data_out->device_private)[i*descA->mb+i] += params_tlr->add_diag;
            }
        }
    }

    /* Calculate the Frobenius norm of this tile */
    {
        int tid = es->th_id;
        double current_value = 0.0;
        params_tlr->norm_tile[n*params_tlr->NT+m] = 0.0;
        
        // Compute norm based on precision type
        if( IS_ALLOCATE_DP(m, n) ) { 
            for(int j = 0; j < descA->nb; j++) {
                for(int i = 0; i < descA->mb; i++) {
                    current_value = ((double *)this_task->data._f_D.data_out->device_private)[j*descA->mb+i];
                    params_tlr->norm_tile[n*descA->nt+m] += current_value * current_value; 
                }
            }
        } else {
            for(int j = 0; j < descA->nb; j++) {
                for(int i = 0; i < descA->mb; i++) {
                    current_value = ((float *)this_task->data._f_D.data_out->device_private)[j*descA->mb+i];
                    params_tlr->norm_tile[n*descA->nt+m] += current_value * current_value;
                }
            }
        }

        // Accumulate norm contribution and compute square root
        norm[tid] += params_tlr->norm_tile[n*descA->nt+m];
        params_tlr->norm_tile[n*descA->nt+m] = sqrt(params_tlr->norm_tile[n*descA->nt+m]);

        // Reset norm accumulation for tiles far from diagonal (memory optimization)
        if( m - n >= descA->nt * PORTION_NORM )
            norm[tid] = 0.0;
    }
}
END


/**************************************************
 **************************************************/
READ_R(m, n)

// Execution space
m = params_tlr->band_size_dense .. descA->mt-1
n = 0 .. m-params_tlr->band_size_dense

:descAr(m, n)

READ R <- descAr(m, n)             
       -> R generate_approximate_L(m, n)     [ type_remote = AR ]

BODY
{
}
END


/**************************************************
 **************************************************/
WRITE_R(m, n)

// Execution space
m = params_tlr->band_size_dense .. descA->mt-1
n = 0 .. m-params_tlr->band_size_dense

:descAr(m, n)

RW R <- R generate_approximate_L(m, n)       [ type_remote = AR ]
     -> descAr(m, n)                         

BODY
{
}
END


/**************************************************
 * generate and approximate lower triangular part *
 **************************************************/
generate_approximate_L(m, n) [high_priority = on]

// Execution space
m = params_tlr->band_size_dense .. descA->mt-1
n = 0 .. m-params_tlr->band_size_dense

// Parallel partitioning
:descA(m, n)

// Parameters
RW R <- R READ_R(m, n)             [ type_remote = AR ]
     -> R WRITE_R(m, n)            [ type_remote = AR ]

READ A <- NULL                     [ type_remote = UV ]

BODY
{
    int size = 0;
    int ldU = BLKLDD(descA, m);
    int ldV = BLKLDD(descA, m);
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int tempnn = n == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    void *U = parsec_private_memory_pop(uv_work);
    void *tmp_D = parsec_private_memory_pop(d_work);
    void *work = parsec_private_memory_pop(rsvd_work);
    void *iwork = parsec_private_memory_pop(rsvd_iwork);
    int rank = -1;
    void *V = (void *)U + descA->mb * params_tlr->maxrank * sizeof(double);

#if GENERATE_RANDOM_DATA 
    CORE_dplgsy(
            params_tlr->N, tempmm, tempnn, tmp_D, ldU,
            descA->m, m*descA->mb, n*descA->nb, 3872 );
#elif !GENOMICS
    params_kernel->kernel(tempmm, tempnn, params_kernel->index + m*descA->mb,
		    params_kernel->index + n*descA->mb, params_kernel->data, params_kernel->data, tmp_D,
		    tempmm);
#else   //TODO Rabab, I need to know how can I make realloc
    memcpy((void *)tmp_D,
		    (void *)this_task->data._f_A.data_out->device_private, descA->mb * descA->mb * sizeof(double));
#endif

    /* Calcuate the global norm */ 
    if( 1 || params_tlr->adaptive_decision ) {
	    int tid = es->th_id;
	    double current_value = 0.0;
	    params_tlr->norm_tile[n*descA->nt+m] = 0.0;

	    for(int j = 0; j < descA->nb; j++) {
		    for(int i = 0; i < descA->mb; i++) {
                current_value = ((double *)tmp_D)[j*descA->mb+i];
                //norm[tid] += current_value * current_value;
                params_tlr->norm_tile[n*descA->nt+m] += current_value * current_value;
            }
        }

        norm[tid] += params_tlr->norm_tile[n*descA->nt+m];
        params_tlr->norm_tile[n*descA->nt+m] = sqrt(params_tlr->norm_tile[n*descA->nt+m]);

        if( m - n >= descA->nt*PORTION_NORM )
            norm[tid] = 0.0;
    }

	// Check whether all values are zero
    int flag = 0;
    for(int j = 0; j < descA->nb; j++) {
            for(int i = 0; i < descA->mb; i++) {
                    if( ((double *)tmp_D)[j*descA->mb+i] > 1.0e-14 ) {
                            flag = 1;
                            break;
                    }
            }
    }

#if 1
    if( 1 || flag != 0 ) {
	    starsh_dense_dlrrsdd(tempmm, tempnn, tmp_D, tempmm, U, ldU, V, ldV, &rank,
			    params_tlr->maxrank, rsvd_oversample, params_tlr->fixedacc, work, rsvd_lwork, iwork);
    } else {
	    rank = 0;
	    printf("%d %d rank_is_0\n", m, n);
    }
#else
    int maxrank_used = hicma_parsec_min(100, params_tlr->maxrank);
    while( 1 ) {
        starsh_dense_dlrrsdd(tempmm, tempnn, tmp_D, tempmm, U, ldU, V, ldV, &rank,
                maxrank_used, rsvd_oversample, params_tlr->fixedacc, work, rsvd_lwork, iwork);
        maxrank_used *= 2;
        maxrank_used = hicma_parsec_min( descA->nb / 2, maxrank_used );
        if( rank != -1 || maxrank_used > descA->nb / 2 ) break;
        params_kernel->kernel(tempmm, tempnn, params_kernel->index + m*descA->mb,
                params_kernel->index + n*descA->mb, params_kernel->data, params_kernel->data, tmp_D,
                tempmm);
        printf("%d %d: maxrank_used %d rank %d\n", m, n, maxrank_used, rank);
    } 
#endif

    if(rank == -1) {
        printf("Tile(%d, %d) is dense, try increasing NB or params_tlr->maxrank \n", m, n);
        params_tlr->info = -1;
    } else {
        /* Update R and size */
        *(int *)R = rank;

        if(params_tlr->send_full_tile == 1){ /* Storage of UV tiles is MB by maxrank by 2 */
            size = descA->mb * params_tlr->maxrank * 2;
        } else {
            size = descA->mb * parsec_imin(params_tlr->maxrank, rank) * 2;
        }

        /* New data_copy and allocate memory for descA(m, n); 
         * For off band, if send_full_tile, allocate mb * maxrank * 2,
         * else, size = mb * min(maxrank, rank) * 2
         */
        this_task->data._f_A.data_out = parsec_data_copy_new(data_of_descA(m, n), 0, PARSEC_matrix_compress_UV_ADT->opaque_dtt, PARSEC_DATA_FLAG_PARSEC_MANAGED);
        this_task->data._f_A.data_out->device_private = calloc(size, sizeof(double));

        /* New nb_elts for data_of(m, n) */
        (data_of_descA(m, n))->nb_elts = size * sizeof(double);

	if( 0 != rank ) {
		/* Copy U to A */
		memcpy((void *)this_task->data._f_A.data_out->device_private,
				(void *)U, descA->mb * rank * sizeof(double));

		/* Copy V to A */
		memcpy((void *)this_task->data._f_A.data_out->device_private + descA->mb * rank * sizeof(double),
				(void *)V, descA->mb * rank * sizeof(double));
	}
    }

    parsec_private_memory_push(uv_work, U);
    parsec_private_memory_push(d_work, tmp_D);
    parsec_private_memory_push(rsvd_work, work);
    parsec_private_memory_push(rsvd_iwork, iwork);
}
END

extern "C" %{

/**
 * Generate matrix
 * @return the parsec object to schedule
 */
parsec_taskpool_t*
hicma_parsec_matrix_compress_New( parsec_context_t *parsec,
        hicma_parsec_data_t *data,
        hicma_parsec_params_t *params_tlr,
        starsh_params_t *params_kernel,
        double *norm_tmp)
{


    #if PREDICTION
        parsec_tiled_matrix_t *A = parsec_tiled_matrix_submatrix(  (parsec_tiled_matrix_t *)&data->dcA, 0, 0, params_tlr->NP, params_tlr->NP);
        if( params_tlr->band_size_dense >= A->nt && params_tlr->auto_band == 0 && !params_tlr->adaptive_memory ) {
            A = parsec_tiled_matrix_submatrix(  (parsec_tiled_matrix_t *)&data->dcAd, 0, 0, params_tlr->NP, params_tlr->NP); 
        }
    #else
        parsec_tiled_matrix_t *A = (parsec_tiled_matrix_t *)&data->dcA;;
        if( params_tlr->band_size_dense >= A->nt && params_tlr->auto_band == 0 && !params_tlr->adaptive_memory ) {
        A = (parsec_tiled_matrix_t *)&data->dcAd;    
        }
    #endif

    parsec_tiled_matrix_t *Ar = (parsec_tiled_matrix_t *)&data->dcAr;

    /* Check input arguments */
    if (params_tlr->uplo != PlasmaLower) {
        dplasma_error("STARSH_appr_New", "illegal value of uplo, should be PlasmaLower\n");
        return NULL /*-1*/;
    }

    /* Check params_tlr->band_size_dense */ 
    if( params_tlr->band_size_dense < 1 ) {
        if( 0 == A->super.myrank )
            fprintf(stderr, "\nERROR: band_size_dense should be not less that 1 : %d\n\n", params_tlr->band_size_dense);
        exit(1);
    }

    /* Calculate workspace */
    int rsvd_oversample = 10;
    int mn = rsvd_oversample + params_tlr->maxrank;
    if(mn > A->mb)
        mn = A->mb;
    size_t rsvd_lwork = (4*mn+7) * mn;
    if(rsvd_lwork < A->mb)
        rsvd_lwork = A->mb;
    rsvd_lwork += mn*(3*A->mb+mn+1);
    size_t rsvd_liwork = 8*mn;

    params_tlr->info = 0;
    parsec_matrix_compress_taskpool_t *starsh_gen = parsec_matrix_compress_new(A, Ar, params_tlr, params_kernel);

    starsh_gen->_g_norm = norm_tmp; 
    starsh_gen->_g_rsvd_oversample = rsvd_oversample;
    starsh_gen->_g_rsvd_lwork = rsvd_lwork; 
    starsh_gen->_g_rsvd_liwork = rsvd_liwork; 

    /* Memery pool */
    starsh_gen->_g_uv_work = malloc(sizeof(parsec_memory_pool_t));
    parsec_private_memory_init(starsh_gen->_g_uv_work, (A->mb*params_tlr->maxrank*2)*sizeof(double));

    starsh_gen->_g_d_work = malloc(sizeof(parsec_memory_pool_t));
    parsec_private_memory_init(starsh_gen->_g_d_work, (A->mb*A->mb)*sizeof(double));

    starsh_gen->_g_rsvd_work = malloc(sizeof(parsec_memory_pool_t));
    parsec_private_memory_init(starsh_gen->_g_rsvd_work, rsvd_lwork*sizeof(double));

    starsh_gen->_g_rsvd_iwork = malloc(sizeof(parsec_memory_pool_t));
    parsec_private_memory_init(starsh_gen->_g_rsvd_iwork, rsvd_liwork*sizeof(int));

    /* Arena */
    parsec_add2arena(&starsh_gen->arenas_datatypes[PARSEC_matrix_compress_FULL_ADT_IDX],
                            parsec_datatype_double_t, PARSEC_MATRIX_FULL,
                            1, A->mb, A->mb, A->mb,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    parsec_add2arena(&starsh_gen->arenas_datatypes[PARSEC_matrix_compress_UV_ADT_IDX],
                            parsec_datatype_double_t, PARSEC_MATRIX_FULL,
                            1, A->mb, params_tlr->maxrank*2, A->mb,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    parsec_add2arena(&starsh_gen->arenas_datatypes[PARSEC_matrix_compress_AR_ADT_IDX],
                            parsec_datatype_int_t, PARSEC_MATRIX_FULL,
                            1, 1, 1, 1,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );
    #if PREDICTION
        //free(A);
    #endif
    return (parsec_taskpool_t*)starsh_gen;
}

/* Destructor */
void hicma_parsec_matrix_compress_Destruct(parsec_taskpool_t *taskpool)
{
    parsec_matrix_compress_taskpool_t *matrix_compress_taskpool = (parsec_matrix_compress_taskpool_t *)taskpool;

    parsec_del2arena(&matrix_compress_taskpool->arenas_datatypes[PARSEC_matrix_compress_FULL_ADT_IDX]);
    parsec_del2arena(&matrix_compress_taskpool->arenas_datatypes[PARSEC_matrix_compress_UV_ADT_IDX]);
    parsec_del2arena(&matrix_compress_taskpool->arenas_datatypes[PARSEC_matrix_compress_AR_ADT_IDX]);

    parsec_private_memory_fini( matrix_compress_taskpool->_g_uv_work );
    parsec_private_memory_fini( matrix_compress_taskpool->_g_d_work );
    parsec_private_memory_fini( matrix_compress_taskpool->_g_rsvd_work );
    parsec_private_memory_fini( matrix_compress_taskpool->_g_rsvd_iwork );

    parsec_taskpool_free(taskpool);
}

/**
 * Generate matrix 
 */
int hicma_parsec_matrix_compress( parsec_context_t *parsec,
        hicma_parsec_data_t *data,
        hicma_parsec_params_t *params_tlr,
        starsh_params_t *params_kernel )
{
    parsec_taskpool_t *parsec_matrix_compress = NULL;

    if( params_tlr->rank == 0 ) {
#if GENERATE_RANDOM_DATA
        fprintf(stderr, YEL "Use GENERATE_RANDOM_DATA\n" RESET);
#else
        fprintf(stderr, YEL "Not GENERATE_RANDOM_DATA and allocate in DP\n" RESET);
#endif
    }

#if PREDICTION
    parsec_tiled_matrix_t *A = parsec_tiled_matrix_submatrix(  (parsec_tiled_matrix_t *)&data->dcA, 0, 0, params_tlr->NP, params_tlr->NP);
    if( params_tlr->band_size_dense >= A->nt && params_tlr->auto_band == 0 && !params_tlr->adaptive_memory ) {
        A = parsec_tiled_matrix_submatrix(  (parsec_tiled_matrix_t *)&data->dcAd, 0, 0, params_tlr->NP, params_tlr->NP); 
    }
#else
    parsec_tiled_matrix_t *A = (parsec_tiled_matrix_t *)&data->dcA;;
    if( params_tlr->band_size_dense >= A->nt && params_tlr->auto_band == 0 && !params_tlr->adaptive_memory ) {
        A = (parsec_tiled_matrix_t *)&data->dcAd;    
    }
#endif

    /* Only for 1 vp */
    assert( parsec->nb_vp == 1 );
    int nb_threads = parsec->virtual_processes[0]->nb_cores;
    double *norm_tmp = (double *)calloc(sizeof(double), nb_threads);

    /* Make sure norm_tile and norm_global is fresh */
    params_tlr->norm_global = 0.0;
    memset( params_tlr->norm_tile, 0, A->nt * A->mt * sizeof(double) );

    parsec_matrix_compress = hicma_parsec_matrix_compress_New( parsec, data, params_tlr, params_kernel, norm_tmp ); 

    parsec_context_add_taskpool(parsec, parsec_matrix_compress);
    parsec_context_start(parsec);
    parsec_context_wait(parsec);
    hicma_parsec_matrix_compress_Destruct(parsec_matrix_compress);

    /* Reduce to the global norm */
    double norm_process = 0.0;
    for( int i = 0; i < nb_threads; i++ ) {
        norm_process += norm_tmp[i];
    }

    MPI_Allreduce(MPI_IN_PLACE, params_tlr->norm_tile, A->nt * A->mt, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
    MPI_Allreduce(&norm_process, &params_tlr->norm_global, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
    params_tlr->norm_global = sqrt(params_tlr->norm_global);

    free( norm_tmp );

    if(params_tlr->info != 0) {
        fprintf(stderr, "Error in low rank matrix generation, info:%d\n", params_tlr->info);
        fflush(stdout);
        exit(1);
    }

    #if PREDICTION
        //free(A);
    #endif

    return 0;
}

%}
