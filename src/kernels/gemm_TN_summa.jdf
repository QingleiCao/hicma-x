extern "C" %{
/**
 * @copyright (c) 2023-2025     Saint Louis University (SLU)
 * @copyright (c) 2023-2025     Massachusetts Institute of Technology (MIT)
 * @copyright (c) 2023-2025     Nvidia Corporation
 * @copyright (c) 2018-2025     King Abdullah University of Science and Technology (KAUST)
 * @copyright (c) 2018-2023     The University of Tennessee and The University of Tennessee Research Foundation
 *                              All rights reserved.
 **/

/**
 * @file gemm_TN_summa.jdf
 * @brief JDF (Just Data Flow) implementation for SUMMA-based General Matrix Multiply operation C = alpha * A^T * B + beta * C
 * 
 * This file implements a high-performance GEMM operation using the SUMMA (Scalable Universal Matrix Multiplication Algorithm)
 * algorithm with PaRSEC runtime system. The operation computes: C = alpha * A^T * B + beta * C where:
 * - A^T denotes the transpose of matrix A
 * - B is used as-is (no transpose)
 * - C is the result matrix
 * 
 * Key features:
 * - SUMMA algorithm for better scalability on distributed systems
 * - Ring-based communication pattern for data distribution
 * - GPU acceleration with CUDA support
 * - Mixed precision computation (int8 input, int32 intermediate)
 * - 2D process grid support with P x Q processors
 */

#include "hicma_parsec.h"

/* Define the different shapes this JDF is using */
#define A_SHAPE 0  /**< Shape identifier for matrix A */
#define B_SHAPE 1  /**< Shape identifier for matrix B */
#define C_SHAPE 2  /**< Shape identifier for matrix C */

#include "gemm_TN_summa.h"

/**
 * @brief Hook function that always returns DONE (used for conditional execution)
 * @param task The task being processed
 * @return PARSEC_HOOK_RETURN_DONE
 */
static inline parsec_hook_return_t
always_here(const parsec_task_t* task)
{
    (void)task;
    return PARSEC_HOOK_RETURN_DONE;
}

/**
 * @brief Hook function that always returns NEXT (used for conditional execution)
 * @param task The task being processed
 * @return PARSEC_HOOK_RETURN_NEXT
 */
static inline parsec_hook_return_t
never_here(const parsec_task_t* task)
{
    (void)task;
    return PARSEC_HOOK_RETURN_NEXT;
}

%}

/*
 * Global Parameters and Data Descriptors
 * =====================================
 */

/* Keep this first, as in all jdf in this directory, to
 * enable switching between GEMM implementations.
 */
gemm_type [ type = int hidden=on default="HICMA_GEMM_TN_SUMMA" ]  /**< GEMM implementation type identifier for SUMMA */

transA [type = int]  /**< Transpose flag for matrix A (1=transpose, 0=no transpose) */
transB [type = int]  /**< Transpose flag for matrix B (1=transpose, 0=no transpose) */

alpha  [type = float]  /**< Scaling factor for the matrix product A^T * B */
beta   [type = float]  /**< Scaling factor for the existing matrix C */

descA     [type = "const parsec_tiled_matrix_t*"]  /**< Descriptor for input matrix A */

descB     [type = "const parsec_tiled_matrix_t*"]  /**< Descriptor for input matrix B */

descC     [type = "const parsec_tiled_matrix_t*"]  /**< Descriptor for output matrix C */

Cdist  [type = "parsec_data_collection_t *"]  /**< Data collection for distributed matrix C */

params_tlr   [ type = "hicma_parsec_params_t *" ]  /**< HiCMA PaRSEC parameters */

/* GPU workspace */
ws_gpu       [ type = "void *" hidden = on default = NULL ]  /**< GPU workspace for CUDA/HIP operations */

/*Workspace*/
p_work_int       [ type = "parsec_memory_pool_t *" hidden = on default = NULL ]  /**< Memory pool for integer workspace */

/* GPU number and index */
nb_cuda_devices      [ type = "int"   hidden = on default = 0 ]  /**< Number of available CUDA devices */
cuda_device_index    [ type = "int *" hidden = on default = "NULL"]  /**< Array of CUDA device indices */

P      [type = "int" hidden=on default="((parsec_matrix_block_cyclic_t*)descC)->grid.rows"]  /**< Process grid rows (SUMMA dimension) */
Q      [type = "int" hidden=on default="((parsec_matrix_block_cyclic_t*)descC)->grid.cols"]  /**< Process grid columns (SUMMA dimension) */

/* Look ahead on both dimensions */
lookP  [type = "int" hidden=on default="dplasma_aux_getGEMMLookahead(descC)"]  /**< Look-ahead depth for P dimension */
lookQ  [type = "int" hidden=on default="dplasma_aux_getGEMMLookahead(descC)"]  /**< Look-ahead depth for Q dimension */


/**************************************************
 *               Define Arena                     *
 * ===============================================
 * Arena definition for the SUMMA GEMM operation.
 * This creates a virtual execution space for the computation.
 **************************************************/
my_arena(k)

// Execution space - single iteration for arena initialization
k = 0 .. 0

// Parallel partitioning - maps to the first tile of matrix C
:descC(0, 0)

// Parameters - dummy read for arena setup
READ A1 <- NULL       [ type = FULL_I8 ]   /**< Dummy read for int8 data */

BODY
{
}
END

/**************************************************
 *                       READ_A                   *
 * ===============================================
 * Task for reading tiles from matrix A in SUMMA algorithm.
 * This task reads a tile A(k,m) and starts the ring distribution
 * to the appropriate column of the process grid.
 **************************************************/
READ_A(k, m)  [profile = off]

// Execution space - iterate over all tiles in matrix A
k = 0 .. descA->mt-1  /**< Row index in matrix A */
m = 0 .. descA->nt-1  /**< Column index in matrix A */

// Parallel partitioning - each task operates on one tile
: descA(k, m)

// Data flow - read tile and start ring distribution
READ A <- descA(k, m) 
       -> A RING_A(k, m, k%Q) /* dep OUT: rely on datacopy dtt for sending */  [type_remote=FULL_I8]  /**< Send to ring based on k%Q */

BODY
{
    printlog("rank %u <- A(%d,%d)\n", ((parsec_data_collection_t*)descA)->myrank, k, m);
}
END

/**************************************************
 *                       RING_A                   *
 * ===============================================
 * Ring distribution task for matrix A in SUMMA algorithm.
 * This task implements the ring communication pattern for distributing
 * matrix A tiles across the process grid columns.
 **************************************************/
RING_A(k, m, q)  [profile = off]

// Execution space - iterate over all tiles and process grid columns
k = 0 .. descA->mt-1  /**< Row index in matrix A */
m = 0 .. descA->nt-1  /**< Column index in matrix A */
q = 0 .. Q-1          /**< Process grid column index */
prevq = (q-1+Q)%Q     /**< Previous process in the ring */
nextq = (q+1)%Q       /**< Next process in the ring */

// Parallel partitioning - each task operates on one process grid position
: Cdist(m, q)

// Data flow - ring communication pattern
READ A <- (k%Q == q) ? A READ_A(k, m) : A RING_A(k, m, prevq) [type_remote=FULL_I8]  /**< Receive from READ_A or previous ring */
       -> A GEMM(m, q .. descC->nt-1 .. Q, k)                 [type_remote=FULL_I8]  /**< Send to all GEMM tasks in this column */
       -> (nextq != (k%Q)) ? A RING_A(k, m, nextq)            [type_remote=FULL_I8]  /**< Forward to next process in ring */

// Control flow - look-ahead mechanism
CTL ctla <- (k >= lookQ) ? ctla GEMM(m, q .. descC->nt-1 .. Q, k-lookQ)  /**< Control signal for GEMM tasks */

BODY
{
    printlog("rank %u <- A(%d,%d)\n", ((parsec_data_collection_t*)descA)->myrank, k, m);
}
END

/**************************************************
 *                       READ_B                   *
 * ===============================================
 * Task for reading tiles from matrix B in SUMMA algorithm.
 * This task reads a tile B(k,n) and starts the ring distribution
 * to the appropriate row of the process grid.
 **************************************************/
READ_B(k, n) [profile = off]

// Execution space - iterate over all tiles in matrix B
k = 0 .. descB->mt-1  /**< Row index in matrix B */
n = 0 .. descB->nt-1  /**< Column index in matrix B */

// Parallel partitioning - each task operates on one tile
: descB(k, n)

// Data flow - read tile and start ring distribution
READ B <- descB(k, n) 
       -> B RING_B(k, n, k%P) /* dep OUT: rely on datacopy dtt for sending */ //[type_remote=FULL_I8]  /**< Send to ring based on k%P */

BODY
{
     printlog("rank %u <- B(%d,%d)\n", ((parsec_data_collection_t*)descB)->myrank, k, n);
}
END

/**************************************************
 *                       RING_B                   *
 * ===============================================
 * Ring distribution task for matrix B in SUMMA algorithm.
 * This task implements the ring communication pattern for distributing
 * matrix B tiles across the process grid rows.
 **************************************************/
RING_B(k, n, p)  [profile = off]

// Execution space - iterate over all tiles and process grid rows
k = 0 .. descB->mt-1  /**< Row index in matrix B */
n = 0 .. descB->nt-1  /**< Column index in matrix B */
p = 0 .. P-1          /**< Process grid row index */
prevp = (p-1+P)%P     /**< Previous process in the ring */
nextp = (p+1)%P       /**< Next process in the ring */

// Parallel partitioning - each task operates on one process grid position
: Cdist(p, n)

// Data flow - ring communication pattern
READ B <- (k%P == p) ? B READ_B(k, n) : B RING_B(k, n, prevp) [type_remote=FULL_I8]  /**< Receive from READ_B or previous ring */
       -> B GEMM(p .. descC->mt-1 .. P, n, k)               [type_remote=FULL_I8]  /**< Send to all GEMM tasks in this row */
       -> (nextp != (k%P)) ? B RING_B(k, n, nextp)          [type_remote=FULL_I8]  /**< Forward to next process in ring */

// Control flow - look-ahead mechanism
CTL ctlb <- (k >= lookP) ? ctlb GEMM(p .. descC->mt-1 .. P, n, k-lookP)  /**< Control signal for GEMM tasks */

BODY
{
     printlog("rank %u <- B(%d,%d)\n", ((parsec_data_collection_t*)descB)->myrank, k, n);
}
END

/**************************************************
 *                       GEMM                     *
 * ===============================================
 * Main computation task for SUMMA GEMM operation.
 * Performs: C = alpha * A^T * B + beta * C
 * 
 * This task implements the SUMMA algorithm with:
 * - Ring-based communication for data distribution
 * - Mixed-precision computation (int8 input, int32 intermediate)
 * - GPU acceleration with CUDA support
 * - 2D process grid support
 **************************************************/
GEMM(m, n, k) [flops = inline_c%{ return FLOPS_ZGEMM(CLEAN_MB(descC, m), CLEAN_NB(descC, n), CLEAN_MB(descA, k)); %}]

// Execution space - iterate over all tiles in the computation
m = 0 .. descC->mt-1  /**< Row index in result matrix C */
n = 0 .. descC->nt-1  /**< Column index in result matrix C */
k = 0 .. descA->mt-1  /**< Panel index for the k-loop (outer product iteration) */

// Parallel partitioning - each task operates on one tile of matrix C
: descC(m, n)

// Parameters - data dependencies and flow
READ A <- A RING_A(k, m, n%Q)                         [type_remote=FULL_I8]  /**< Read A from ring distribution */
READ B <- B RING_B(k, n, m%P)                         [type_remote=FULL_I8]  /**< Read B from ring distribution */
RW   C <- (k == 0)             ? descC(m, n)          /**< Read initial C from matrix */
       <- (k != 0)             ? C GEMM( m, n, k-1 )  /**< Read C from previous iteration */
       -> (k == (descA->mt-1)) ? descC(m, n)          /**< Write final result back to matrix C */
       -> (k != (descA->mt-1)) ? C GEMM( m, n, k+1 )  /* dep OUT: rely on datacopy dtt for sending */  /**< Pass C to next iteration */

// Control flow - look-ahead mechanism for better performance
CTL ctla -> (k < (descA->mt-lookQ)) ? ctla RING_A(k+lookQ, m, n%Q)  /**< Control signal for A data prefetching */
CTL ctlb -> (k < (descA->mt-lookP)) ? ctlb RING_B(k+lookP, n, m%P)  /**< Control signal for B data prefetching */

BODY [type=CUDA
      A.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      B.size=%{ return descB->mb*descB->nb*parsec_datadist_getsizeoftype(descB->mtype);%}
      C.size=%{ return descC->mb*descC->nb*parsec_datadist_getsizeoftype(descC->mtype);%}]
{
    // Set up scaling factors
    float lalpha = alpha;                    /**< Scaling factor for A^T * B */
    float lbeta  = (k == 0) ? beta : 1.0;   /**< Scaling factor for C (beta only on first iteration) */

    // Calculate actual tile dimensions (handle edge cases)
    int tempmm = m == descC->mt-1 ? descC->m - m * descC->mb : descC->mb;  /**< Actual rows in C tile */
    int tempnn = n == descC->nt-1 ? descC->n - n * descC->nb : descC->nb;  /**< Actual columns in C tile */
    int tempkk = k == descA->mt-1 ? descA->m - k * descA->mb : descA->mb;  /**< Actual columns in A tile */
    int ldak = descA->mb;   /**< Leading dimension of A tile */
    int ldbk = descB->mb;   /**< Leading dimension of B tile */
    int ldcm = descC->mb;   /**< Leading dimension of C tile */

    /* Get CUDA BLAS handle and set stream */
    parsec_potrf_workspace_t *_ws_gpu = (parsec_potrf_workspace_t *)ws_gpu;
    parsec_potrf_stream_workspace_t *stream_found = lookup_gpu_workspace(cuda_device, cuda_stream, _ws_gpu);
    cublasHandle_t handle = stream_found->handle_cublas;
    cublasSetStream( handle, cuda_stream->cuda_stream );

    // Convert scaling factors to integer for mixed-precision computation
    int ialpha=(int)lalpha;
    int ibeta=(int)lbeta;
    
    cublasStatus_t status;
#if 0
    // Alternative double precision implementation (commented out)
    status = cublasDgemm( handle, CUBLAS_OP_T, CUBLAS_OP_N,
                        tempmm, tempnn, tempkk,
                        &lalpha, A, ldak,
                        B, ldbk,
                        &lbeta,  C, ldcm );
    //HiCMA_CUDA_CHECK_ERROR( "cublasSgemm7", status);
#else
    // Mixed precision implementation: int8 input -> int32 output
    status = cublasGemmEx(handle, CUBLAS_OP_T, CUBLAS_OP_N,
                                   tempmm, tempnn, tempkk,
                                   &ialpha, A, CUDA_R_8I, ldak,      /**< A as int8 */
                                            B, CUDA_R_8I, ldbk,      /**< B as int8 */
                                   &ibeta, C, CUDA_R_32I, ldcm,      /**< C as int32 */
                                            CUDA_R_32I, CUBLAS_GEMM_DEFAULT);
#endif
    PARSEC_CUDA_CHECK_ERROR( "cublasSgemm ", status, {return PARSEC_HOOK_RETURN_ERROR;} );
}
END
