extern "C" %{
/**
 * @copyright (c) 2023-2025     Saint Louis University (SLU)
 * @copyright (c) 2023-2025     Massachusetts Institute of Technology (MIT)
 * @copyright (c) 2023-2025     Nvidia Corporation
 * @copyright (c) 2018-2025     King Abdullah University of Science and Technology (KAUST)
 * @copyright (c) 2018-2023     The University of Tennessee and The University of Tennessee Research Foundation
 *                              All rights reserved.
 **/

#include "hicma_parsec.h"

%}

/** Cast diagonal tiles from single precision (FP32) to double precision (FP64)
 *  This task converts diagonal matrix tiles from single precision to double precision
 *  to ensure numerical accuracy for critical diagonal operations.
 */
descA        [ type = "parsec_tiled_matrix_t*" ]  // Matrix descriptor containing tile information
params_tlr   [ type = "hicma_parsec_params_t *" ] // Runtime parameters including GPU configuration

/**************************************************
 * Task definition for casting diagonal tiles
 **************************************************/
task_cast(m)

// Execution space: iterate over diagonal tiles only (m = m)
m = 0 .. descA->mt-1

// Parallel partitioning: each diagonal tile is processed independently
:descA(m, m)

// Parameters: read-write access to diagonal tile A(m,m)
RW   A <- descA(m, m) 
       -> descA(m, m)

BODY
{
    /* Allocate new memory for double precision data */
    double *new_memory;
    
    // Choose memory allocation strategy based on GPU availability
    if( params_tlr->gpus > 0 ) {
        // GPU-accelerated environment: use pinned host memory for better transfer performance
#if defined(PARSEC_HAVE_DEV_CUDA_SUPPORT)
        cudaMallocHost((void**)&new_memory, descA->mb * descA->mb * sizeof(double));
#endif

#if defined(PARSEC_HAVE_DEV_HIP_SUPPORT)
        hipHostMalloc((void**)&new_memory, descA->mb * descA->mb * sizeof(double), hipHostMallocDefault);
#endif
    } else {
        // CPU-only environment: use standard heap allocation
        new_memory = malloc( descA->mb * descA->mb * sizeof(double) );
    }
    
    // Convert single precision data to double precision using optimized binary conversion
    convert_s2d_binary_CPU(new_memory, this_task->data._f_A.data_out->device_private, descA->mb, descA->mb);

    /* Free previous single precision memory and attach new double precision memory */
    if( params_tlr->gpus > 0 ) {
        // Free pinned host memory allocated for GPU environment
#if defined(PARSEC_HAVE_DEV_CUDA_SUPPORT) || defined(PARSEC_HAVE_DEV_HIP_SUPPORT)
        cudaFreeHost( this_task->data._f_A.data_out->device_private );
#endif
    } else {
        // Free standard heap memory
        free( this_task->data._f_A.data_out->device_private );
    }
    
    // Update tile data pointer to point to new double precision memory
    this_task->data._f_A.data_out->device_private = new_memory;

    // Update element count to reflect double precision storage (8 bytes per element)
    this_task->data._f_A.data_out->original->nb_elts = descA->mb * descA->mb * sizeof(double);
}
END


extern "C" %{

/**
 * Create a new taskpool for casting diagonal tiles from single to double precision
 * 
 * This function creates and initializes a PaRSEC taskpool that will convert
 * all diagonal tiles of the matrix from single precision (FP32) to double 
 * precision (FP64) for improved numerical accuracy.
 *
 * @param [in] dcA:      tiled matrix descriptor containing the matrix to be converted
 * @param [in] params:   runtime parameters including GPU configuration and memory settings
 * @return the parsec taskpool object to schedule, or NULL on failure
 */
parsec_taskpool_t*
parsec_cast_double_diag_New(parsec_tiled_matrix_t *dcA, hicma_parsec_params_t *params )
{
    parsec_cast_double_diag_taskpool_t* taskpool = NULL;
    taskpool = parsec_cast_double_diag_new(dcA, params);
    return (parsec_taskpool_t*)taskpool; 
}

/**
 * Destructor for the cast double diagonal taskpool
 * 
 * Properly cleans up and deallocates the taskpool and all associated resources.
 * This function should be called after the taskpool execution is complete.
 *
 * @param [inout] taskpool: the parsec taskpool object to destroy and deallocate
 */
void parsec_cast_double_diag_Destruct(parsec_taskpool_t *taskpool)
{
    parsec_cast_double_diag_taskpool_t *cast_double_diag_taskpool = (parsec_cast_double_diag_taskpool_t *)taskpool;
    parsec_taskpool_free(taskpool);
}

/**
 * High-level interface to cast diagonal tiles from single precision to double precision
 * 
 * This function provides a complete workflow for converting diagonal matrix tiles
 * from FP32 to FP64 precision. It creates the taskpool, schedules execution,
 * waits for completion, and properly cleans up resources.
 * 
 * The conversion is performed in-place, replacing the original single precision
 * data with double precision data while maintaining the same matrix structure.
 *
 * @param [in] parsec:   PaRSEC runtime context for task scheduling and execution
 * @param [inout] dcA:   tiled matrix descriptor - diagonal tiles will be converted in-place
 * @param [in] params:   runtime parameters including GPU configuration and memory settings
 * @return 0 on success, non-zero on failure
 */
int hicma_parsec_cast_double_diag(parsec_context_t *parsec,
        parsec_tiled_matrix_t *dcA,
        hicma_parsec_params_t *params )
{
    parsec_taskpool_t *parsec_cast_double_diag = NULL;

    // Create the taskpool for diagonal tile conversion
    parsec_cast_double_diag = parsec_cast_double_diag_New(dcA, params);

    // Execute the conversion if taskpool creation was successful
    if( parsec_cast_double_diag != NULL ){
        parsec_context_add_taskpool(parsec, parsec_cast_double_diag);
        parsec_context_start(parsec);
        parsec_context_wait(parsec);
        parsec_cast_double_diag_Destruct(parsec_cast_double_diag);
    }

    return 0;
}

%}
