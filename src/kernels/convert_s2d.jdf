extern "C" %{
/*
 * @copyright (c) 2023-2025     Saint Louis University (SLU)
 * @copyright (c) 2023-2025     Massachusetts Institute of Technology (MIT)
 * @copyright (c) 2023-2025     Nvidia Corporation
 * @copyright (c) 2018-2025     King Abdullah University of Science and Technology (KAUST)
 * @copyright (c) 2018-2023     The University of Tennessee and The University of Tennessee Research Foundation
 *                              All rights reserved.
 */

#include "hicma_parsec.h"

%}

// Matrix descriptor for the main matrix (single precision input)
descA         [ type = "parsec_tiled_matrix_t *" ]
// Matrix descriptor for rank information (aligned with descA)
descAr        [ type = "parsec_tiled_matrix_t *" aligned = descA ]
// Decision matrix specifying which tiles need conversion
decisions     [ type = "uint16_t *" ]
// Maximum rank for low-rank representations
maxrank       [ type = "int" ]
// Array storing rank information for each tile
rank_array    [ type = "int *" ]
// Parameters for TLR (Tile Low Rank) operations
params_tlr    [ type = "hicma_parsec_params_t *" ]

// Task definition for converting single precision to double precision
Convert_s2d(m, n)

// Iterate over lower triangular matrix tiles only
m = 0 .. descA->lmt-1
n = 0 .. m

: descA(m, n)

// Conditional read-write access based on decision matrix
// Only process tiles that need conversion to double precision
RW A <- (%{ return DENSE_SP == decisions[n*descA->lmt+m]; %} || %{ return DENSE_HP == decisions[n*descA->lmt+m]; %} || %{ return DENSE_FP8 == decisions[n*descA->lmt+m]; %} || %{ return LOW_RANK_SP == decisions[n*descA->lmt+m]; %})? descA(m, n): NULL        
     -> (%{ return DENSE_SP == decisions[n*descA->lmt+m]; %} || %{ return DENSE_HP == decisions[n*descA->lmt+m]; %} || %{ return DENSE_FP8 == decisions[n*descA->lmt+m]; %} || %{ return LOW_RANK_SP == decisions[n*descA->lmt+m]; %})? descA(m, n)              

// Read rank information for low-rank tiles
READ Ar <- (%{ return LOW_RANK_SP == decisions[n*descA->lmt+m]; %})? descAr(m, n): NULL     [ type  = AR ]

// Define remote arena types for different data formats
READ A1 <- NULL       [ type_remote = FULL_DP ]  // Full double precision
READ A2 <- NULL       [ type_remote = FULL_SP ]  // Full single precision
READ A3 <- NULL       [ type_remote = UV_DP ]    // Low-rank U*V double precision
READ A4 <- NULL       [ type_remote = UV_SP ]    // Low-rank U*V single precision

BODY
{
    // Handle dense matrix tiles that need conversion to double precision
    if( DENSE_SP == decisions[n*descA->lmt+m] || DENSE_HP == decisions[n*descA->lmt+m] || DENSE_FP8 == decisions[n*descA->lmt+m]) {
        void *A_save = A;

        if( params_tlr->check || !params_tlr->adaptive_memory ) {
            // In-place conversion (unary operation) - note: this is actually s2d, not d2s
            convert_s2d_unary_CPU(A, descA->mb, descA->mb);
        } else {
            // Allocate new memory and convert to double precision
            if( params_tlr->gpus > 0 ) {
#if defined(PARSEC_HAVE_DEV_CUDA_SUPPORT)
                cudaMallocHost((void**)&this_task->data._f_A.data_out->device_private, descA->mb * descA->mb * sizeof(double));
#endif

#if defined(PARSEC_HAVE_DEV_HIP_SUPPORT)
                hipHostMalloc((void**)&this_task->data._f_A.data_out->device_private, descA->mb * descA->mb * sizeof(double), hipHostMallocDefault);
#endif
            } else {
                this_task->data._f_A.data_out->device_private = malloc(descA->mb * descA->mb * sizeof(double));
            }

            // Update element count for double precision
            this_task->data._f_A.data_out->original->nb_elts = descA->mb * descA->nb * sizeof(double);
            
            // Convert from single to double precision using LAPACK
            LAPACKE_slag2d( LAPACK_COL_MAJOR, descA->mb, descA->nb, A_save, descA->mb, this_task->data._f_A.data_out->device_private, descA->mb );

            // Free old single precision memory
            if( params_tlr->gpus > 0 ) {
#if defined(PARSEC_HAVE_DEV_CUDA_SUPPORT) || defined(PARSEC_HAVE_DEV_HIP_SUPPORT)
                cudaFreeHost(A_save);
#endif
            } else {
                free( A_save );
            }
        }

    } else if( LOW_RANK_SP == decisions[n*descA->lmt+m] ) {
        // Handle low-rank matrix tiles that need conversion to double precision
        int rank = ((int *)Ar)[0];
        int rank_old = rank_array[n*descA->lmt+m];
        void *A_save = A;

        // Low rank does not support !adaptive_memory because of reallocation in Cholesky
        {
            // Allocate new memory and convert low-rank tile to double precision
            // Always reallocate because rank may have grown in single precision
            // TODO: implement a better memory management strategy
            //printf("s2d %d %d : old_rank %d new_rank %d\n", m, n, rank_old, rank);
            this_task->data._f_A.data_out->device_private = malloc( descA->mb * rank * 2 * sizeof(double) );
            this_task->data._f_A.data_out->original->nb_elts = descA->mb * rank * 2 * sizeof(double);
            
            // Convert low-rank U*V format from single to double precision
            LAPACKE_slag2d( LAPACK_COL_MAJOR, descA->mb, rank * 2, A_save, descA->mb, this_task->data._f_A.data_out->device_private, descA->mb );
            
            // Free old single precision memory
            free( A_save );
        }
    }
}
END

extern "C" %{

/**
 * @param [in] A:    the data, already distributed and allocated
 * @return the parsec object to schedule.
 */
parsec_taskpool_t*
hicma_parsec_convert_s2d_New(parsec_context_t *parsec,
        hicma_parsec_data_t *data,
        hicma_parsec_params_t *params_tlr)
{
    parsec_taskpool_t* convert_s2d_taskpool;
    parsec_convert_s2d_taskpool_t* taskpool = NULL;
    uint16_t *decisions = params_tlr->decisions;
    int maxrank = params_tlr->maxrank;
    int *rank_array = params_tlr->rank_array;

    parsec_tiled_matrix_t *A = (parsec_tiled_matrix_t *)&data->dcA;
    if( params_tlr->band_size_dense >= params_tlr->NT && params_tlr->auto_band == 0 && !params_tlr->adaptive_memory ) {
        A = (parsec_tiled_matrix_t *)&data->dcAd;
    }
    parsec_tiled_matrix_t *Ar = (parsec_tiled_matrix_t *)&data->dcAr;

    taskpool = parsec_convert_s2d_new(A, Ar, decisions, maxrank, rank_array, params_tlr);
    convert_s2d_taskpool = (parsec_taskpool_t*)taskpool;

    parsec_add2arena(&taskpool->arenas_datatypes[PARSEC_convert_s2d_FULL_DP_ADT_IDX],
                            parsec_datatype_double_t, PARSEC_MATRIX_FULL,
                            1, A->mb, A->nb, A->mb,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    parsec_add2arena(&taskpool->arenas_datatypes[PARSEC_convert_s2d_FULL_SP_ADT_IDX],
                            parsec_datatype_float_t, PARSEC_MATRIX_FULL,
                            1, A->mb, A->nb, A->mb,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    parsec_add2arena(&taskpool->arenas_datatypes[PARSEC_convert_s2d_UV_DP_ADT_IDX],
                            parsec_datatype_double_t, PARSEC_MATRIX_FULL,
                            1, A->mb, maxrank*2, A->mb,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    parsec_add2arena(&taskpool->arenas_datatypes[PARSEC_convert_s2d_UV_SP_ADT_IDX],
                            parsec_datatype_float_t, PARSEC_MATRIX_FULL,
                            1, A->mb, maxrank*2, A->mb,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    parsec_add2arena(&taskpool->arenas_datatypes[PARSEC_convert_s2d_AR_ADT_IDX],
                            parsec_datatype_int_t, PARSEC_MATRIX_FULL,
                            1, 1, 1, 1, 
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    return convert_s2d_taskpool;
}

/**
 * @param [inout] the parsec object to destroy
*/
void hicma_parsec_convert_s2d_Destruct(parsec_taskpool_t *taskpool)
{
    parsec_convert_s2d_taskpool_t *convert_s2d_taskpool = (parsec_convert_s2d_taskpool_t *)taskpool;
    parsec_del2arena(&convert_s2d_taskpool->arenas_datatypes[PARSEC_convert_s2d_FULL_DP_ADT_IDX]);
    parsec_del2arena(&convert_s2d_taskpool->arenas_datatypes[PARSEC_convert_s2d_FULL_SP_ADT_IDX]);
    parsec_del2arena(&convert_s2d_taskpool->arenas_datatypes[PARSEC_convert_s2d_UV_DP_ADT_IDX]);
    parsec_del2arena(&convert_s2d_taskpool->arenas_datatypes[PARSEC_convert_s2d_UV_SP_ADT_IDX]);
    parsec_del2arena(&convert_s2d_taskpool->arenas_datatypes[PARSEC_convert_s2d_AR_ADT_IDX]);
    parsec_taskpool_free(taskpool);
}

/**
 * @brief Init dcA
 * 
 * @param [inout] dcA: the data, already distributed and allocated
 * @param [in] dcAr: the data, already distributed and allocated
 * @param [in] maxrank: max rank 
 */
int hicma_parsec_convert_s2d(parsec_context_t *parsec,
                         hicma_parsec_data_t *data,
                         hicma_parsec_params_t *params_tlr)
{
#if !FOR_CLIMATE_EMULATOR || GENOMICS
    if( GENOMICS || (!params_tlr->check && params_tlr->adaptive_memory) ) {
        VERBOSE_PRINT(params_tlr->rank, params_tlr->verbose,
                (YEL"Do not convert into DP if not checking result, because memory are allocated adaptively based on each tile\n"RESET));
        return 0;
    }
#endif

    parsec_taskpool_t *parsec_convert_s2d = NULL;
    parsec_convert_s2d = hicma_parsec_convert_s2d_New( parsec, data, params_tlr );
    if( parsec_convert_s2d != NULL ){
        parsec_context_add_taskpool(parsec, parsec_convert_s2d);
        parsec_context_start(parsec);
        parsec_context_wait(parsec);
        hicma_parsec_convert_s2d_Destruct(parsec_convert_s2d);
    }

    return 0;
}

%}
